"""
Directory Structure Manager
–û—Ä–≥–∞–Ω–∏–∑—É–µ—Ç –≤—ã—Ö–æ–¥–Ω—ã–µ —Ñ–∞–π–ª—ã –ø–æ –ø–æ–Ω—è—Ç–Ω—ã–º –∫–∞—Ç–µ–≥–æ—Ä–∏—è–º
"""

from pathlib import Path
from datetime import datetime
import json

class DirectoryManager:
    """–£–ø—Ä–∞–≤–ª–µ–Ω–∏–µ —Å—Ç—Ä—É–∫—Ç—É—Ä–æ–π –≤—ã—Ö–æ–¥–Ω—ã—Ö –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–π (V10.0 Updated)"""
    
    def __init__(self, base_output_dir: str):
        self.base_dir = Path(base_output_dir)
        self.session_id = datetime.now().strftime("%Y%m%d_%H%M%S")
        
        # –°–æ–∑–¥–∞–µ–º —Å—Ç—Ä—É–∫—Ç—É—Ä—É
        self.dirs = {
            # –í–æ—Å—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–Ω—ã–µ —Ñ–∞–π–ª—ã –ø–æ —Ç–∏–ø–∞–º
            'json': self.base_dir / '01_RECOVERED_FILES' / 'JSON',
            'csv': self.base_dir / '01_RECOVERED_FILES' / 'CSV',
            'txt': self.base_dir / '01_RECOVERED_FILES' / 'TXT',
            'html': self.base_dir / '01_RECOVERED_FILES' / 'HTML',
            'originals': self.base_dir / '01_RECOVERED_FILES' / 'ORIGINALS',
            'full_original_exfat': self.base_dir / '00_FULL_ORIGINAL_EXFAT',
            'other': self.base_dir / '01_RECOVERED_FILES' / 'OTHER',
            
            # –°–æ–±—Ä–∞–Ω–Ω—ã–µ –∏–∑ —Ñ—Ä–∞–≥–º–µ–Ω—Ç–æ–≤
            'assembled': self.base_dir / '02_ASSEMBLED_FROM_FRAGMENTS',
            
            # –ò–∑–≤–ª–µ—á–µ–Ω–Ω—ã–µ —Å—Å—ã–ª–∫–∏
            'links': self.base_dir / '03_EXTRACTED_LINKS',
            
            # –ú–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ
            'metadata': self.base_dir / '04_METADATA',
            
            # –û—Ç—á–µ—Ç—ã
            'reports': self.base_dir / '05_REPORTS',
            
            # –í—Ä–µ–º–µ–Ω–Ω—ã–µ (–∫–∞–Ω–¥–∏–¥–∞—Ç—ã)
            'candidates_validated': self.base_dir / '06_TEMP_CANDIDATES' / 'validated',
            'candidates_rejected': self.base_dir / '06_TEMP_CANDIDATES' / 'rejected',
            'candidates_failed': self.base_dir / '06_TEMP_CANDIDATES' / 'failed',
        }
        
    def create_structure(self):
        """–°–æ–∑–¥–∞—Ç—å –≤—Å–µ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏"""
        for dir_path in self.dirs.values():
            dir_path.mkdir(parents=True, exist_ok=True)
            
        # –°–æ–∑–¥–∞—Ç—å README –≤ –∫–∞–∂–¥–æ–π –∫–∞—Ç–µ–≥–æ—Ä–∏–∏
        self._create_category_readmes()
        
        # –°–æ–∑–¥–∞—Ç—å –≥–ª–∞–≤–Ω—ã–π –∏–Ω–¥–µ–∫—Å
        self._create_main_index()
        
    def _create_category_readmes(self):
        """–°–æ–∑–¥–∞—Ç—å README –≤ –∫–∞–∂–¥–æ–π –∫–∞—Ç–µ–≥–æ—Ä–∏–∏ (V10.0 Update)"""
        
        readmes = {
            '00_FULL_ORIGINAL_EXFAT': """# üì¶ Full Original exFAT Files

Files fully recovered from exFAT filesystem metadata.

## How it works:
The scanner reads exFAT directory entries (including deleted ones),
follows the FAT cluster chain (or contiguous allocation), and
extracts the complete original file with its original filename.

## What you get:
- **Original filenames** preserved from the filesystem
- **Full file content** ‚Äî not chunks, but complete files
- **Matching `.meta.json`** with forensic metadata (offset, cluster, chain type, SHA256)

## When this folder is empty:
If no exFAT filesystem was detected in the image, or all cluster chains
were damaged, the system falls back to chunk-based recovery in `01_RECOVERED_FILES/`.
""",
            '01_RECOVERED_FILES': """# üìÅ Recovered Files
 
Original files successfully recovered from disk.

## Text/Unknown Recovery (v10.0+):
For TXT and UNKNOWN files, the system now provides two versions:
- `_raw.bin`: The original binary data exactly as found on disk. Use this for forensic analysis.
- `_clean.txt`: A filtered, readable version of the text. Large empty blocks and binary noise have been removed.

## Subfolders:
- **ORIGINALS/** - Professional Forensic Recovery (Original names + Full FAT chains)
- **JSON/** - JSON files containing YouTube links
- **CSV/** - CSV data tables
- **TXT/** - Text files (Clean + Raw)
- **HTML/** - HTML pages
- **OTHER/** - Other formats

## File Naming:
`recovered_NNNN_<type>_<size>.<ext>`

## Metadata:
Every file has a matching `.json` file containing:
- SHA256 hash
- Disk offset
- Quality score (Confidence)
- **Extracted YouTube links** (Check this if the file is unreadable!)
""",
            
            '02_ASSEMBLED_FROM_FRAGMENTS': """# üß© Assembled from Fragments

Files reconstructed by merging multiple fragments found on disk.

## Naming Format:
`assembled_<group>_<fragments>frags_<size>.<ext>`

## Metadata:
- List of all fragment offsets used
- Assembly confidence score
- SHA256 of the final file
""",
            
            '03_EXTRACTED_LINKS': """# üîó Extracted Links

YouTube links extracted from data where full file reconstruction was not possible or in --links-only mode.

## Files:
- `all_links.txt`: Consolidated list of all unique YouTube IDs and URLs found in this session.
- `links_extracted_<offset>.json`: Specific links found at a particular disk location.
""",
            
            '04_METADATA': """# üìä Metadata

Technical details about the recovery session.

## Key Files:
- `session_info.json`: Session parameters and results summary.
- `disk_map.json`: Visualization of data distribution on the disk.
- `clusters.json`: Detailed information about identified data clusters.
""",
            
            '05_REPORTS': """# üìÑ Reports

Professional recovery reports.

## Main Report:
- `recovery_report_<timestamp>.html`: Open this in any web browser for a detailed analysis, charts, and file list.
""",
            
            '06_TEMP_CANDIDATES': """# üîç Temporary Candidates

Intermediate files currently being processed or validated.

**‚ö†Ô∏è This folder is automatically cleaned up after the session ends.**
"""
        }
        
        for dir_name, content in readmes.items():
            readme_path = self.base_dir / dir_name / 'README.md'
            readme_path.write_text(content, encoding='utf-8')
            
    def _create_main_index(self):
        """–°–æ–∑–¥–∞—Ç—å –≥–ª–∞–≤–Ω—ã–π –∏–Ω–¥–µ–∫—Å–Ω—ã–π —Ñ–∞–π–ª (V10.0 Updated)"""
        
        index_content = f"""# üéØ Ultimate File Recovery V10.0 - Session Results
 
**Session ID**: {self.session_id}  
**Date**: {datetime.now().strftime("%Y-%m-%d %H:%M:%S")}

---

## üìÇ Directory Structure

### 00_FULL_ORIGINAL_EXFAT/ üì¶
**Complete files recovered from exFAT filesystem with original names**

These are full files extracted by following exFAT cluster chains.
Check `.meta.json` for forensic details.

### 01_RECOVERED_FILES/ üìÅ
**Recovered original files (Validated)**

Files are organized by type. For TXT/UNKNOWN, look for the `_clean.txt` version for readability.

### 02_ASSEMBLED_FROM_FRAGMENTS/ üß©
**Reconstructed fragmented files**

Combined multi-part data into single files with integrity checks.

### 03_EXTRACTED_LINKS/ üîó
**YouTube Link Repository**

Check `all_links.txt` for a complete list of unique links found across the entire disk.

### 04_METADATA/ üìä
**Technical Session Data**

Logs, disk maps, and performance statistics.

### 05_REPORTS/ üìÑ
**Professional Analysis Reports**

Open `recovery_report_*.html` in your browser for interactive charts and deep-dive analysis.

---

## üöÄ Quick Navigation

### Where are my files?
üëâ `01_RECOVERED_FILES/` - Main storage for recovered data.

### Where is the summary report?
üëâ `05_REPORTS/recovery_report_*.html` - Open in browser.

### I see unreadable symbols?
üëâ Check the matching `.json` file for extracted links, or look for the `_clean.txt` version.

### Where is the full link list?
üëâ `03_EXTRACTED_LINKS/all_links.txt`

---

## ‚ÑπÔ∏è Support
Refer to the `README.md` in each folder for more details. 
**Good luck with your recovery! üçÄ**
"""
        
        index_path = self.base_dir / 'INDEX.md'
        index_path.write_text(index_content, encoding='utf-8')
        
    def get_path(self, category: str) -> Path:
        """–ü–æ–ª—É—á–∏—Ç—å –ø—É—Ç—å –∫ –∫–∞—Ç–µ–≥–æ—Ä–∏–∏"""
        return self.dirs.get(category, self.base_dir)
        
    def save_session_info(self, info: dict):
        """–°–æ—Ö—Ä–∞–Ω–∏—Ç—å –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ —Å–µ—Å—Å–∏–∏"""
        info['session_id'] = self.session_id
        info['created_at'] = datetime.now().isoformat()
        
        session_file = self.dirs['metadata'] / 'session_info.json'
        session_file.write_text(json.dumps(info, indent=2, ensure_ascii=False), encoding='utf-8')
